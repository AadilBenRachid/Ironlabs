{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Challenge-3\" data-toc-modified-id=\"Challenge-3-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Challenge 3</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q1:-How-to-identify-VIP-&amp;-Preferred-Customers?\" data-toc-modified-id=\"Q1:-How-to-identify-VIP-&amp;-Preferred-Customers?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Q1: How to identify VIP &amp; Preferred Customers?</a></span></li><li><span><a href=\"#How-to-label-customers-whose-aggregated-amount_spent-is-in-a-given-quantile-range?\" data-toc-modified-id=\"How-to-label-customers-whose-aggregated-amount_spent-is-in-a-given-quantile-range?-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>How to label customers whose aggregated <code>amount_spent</code> is in a given quantile range?</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Sub-Problem-1:-How-to-aggregate-the--amount_spent-for-unique-customers?\" data-toc-modified-id=\"Sub-Problem-1:-How-to-aggregate-the--amount_spent-for-unique-customers?-1.2.0.1\"><span class=\"toc-item-num\">1.2.0.1&nbsp;&nbsp;</span>Sub Problem 1: How to aggregate the  <code>amount_spent</code> for unique customers?</a></span></li><li><span><a href=\"#Sub-Problem-2:-How-to-select-customers-whose-aggregated-amount_spent-is-in-a-given-quantile-range?\" data-toc-modified-id=\"Sub-Problem-2:-How-to-select-customers-whose-aggregated-amount_spent-is-in-a-given-quantile-range?-1.2.0.2\"><span class=\"toc-item-num\">1.2.0.2&nbsp;&nbsp;</span>Sub Problem 2: How to select customers whose aggregated <code>amount_spent</code> is in a given quantile range?</a></span></li><li><span><a href=\"#Sub-Problem-3:-How-to-label-selected-customers-as-&quot;VIP&quot;-or-&quot;Preferred&quot;?\" data-toc-modified-id=\"Sub-Problem-3:-How-to-label-selected-customers-as-&quot;VIP&quot;-or-&quot;Preferred&quot;?-1.2.0.3\"><span class=\"toc-item-num\">1.2.0.3&nbsp;&nbsp;</span>Sub Problem 3: How to label selected customers as \"VIP\" or \"Preferred\"?</a></span></li></ul></li></ul></li><li><span><a href=\"#Q2:-How-to-identify-which-country-has-the-most-VIP-Customers?\" data-toc-modified-id=\"Q2:-How-to-identify-which-country-has-the-most-VIP-Customers?-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Q2: How to identify which country has the most VIP Customers?</a></span></li><li><span><a href=\"#Q3:-How-to-identify-which-country-has-the-most-VIP+Preferred-Customers-combined?\" data-toc-modified-id=\"Q3:-How-to-identify-which-country-has-the-most-VIP+Preferred-Customers-combined?-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Q3: How to identify which country has the most VIP+Preferred Customers combined?</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3\n",
    "\n",
    "In this challenge we will work on the `Orders` data set (https://drive.google.com/file/d/1xUzMpyQgC5IaK61ehUH2C5P4jCPmLa-s/view?usp=sharing). In your work you will apply the thinking process and workflow we showed you in Challenge 2.\n",
    "\n",
    "You are serving as a Data Analyst at the headquarter of an international fashion goods chain store. Your boss today asked you to do two things for her:\n",
    "\n",
    "**First, identify two groups of customers from the data set.** The first group is **VIP Customers** whose **aggregated expenses** at your global chain stores are **above the 95th percentile** (aka. 0.95 quantile). The second group is **Preferred Customers** whose **aggregated expenses** are **between the 75th and 95th percentile**.\n",
    "\n",
    "**Second, identify which country has the most of your VIP customers, and which country has the most of your VIP+Preferred Customers combined.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: How to identify VIP & Preferred Customers?\n",
    "\n",
    "We start by importing all the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import `Orders` from Ironhack's database into a dataframe variable called `orders`. Print the head of `orders` to overview the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ABR\\Desktop\\Ironlabs\\module1\\Lab_29_Dataframe-Calculations\\challenge-3.ipynb Cellule 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ABR/Desktop/Ironlabs/module1/Lab_29_Dataframe-Calculations/challenge-3.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# your code here\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ABR/Desktop/Ironlabs/module1/Lab_29_Dataframe-Calculations/challenge-3.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m orders \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mABR\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mDownloads\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mOrders.xlsx\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:465\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 465\u001b[0m     data \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mparse(\n\u001b[0;32m    466\u001b[0m         sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[0;32m    467\u001b[0m         header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m    468\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    469\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    470\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m    471\u001b[0m         squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[0;32m    472\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    473\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m    474\u001b[0m         true_values\u001b[39m=\u001b[39;49mtrue_values,\n\u001b[0;32m    475\u001b[0m         false_values\u001b[39m=\u001b[39;49mfalse_values,\n\u001b[0;32m    476\u001b[0m         skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m    477\u001b[0m         nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m    478\u001b[0m         na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m    479\u001b[0m         keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[0;32m    480\u001b[0m         na_filter\u001b[39m=\u001b[39;49mna_filter,\n\u001b[0;32m    481\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    482\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    483\u001b[0m         date_parser\u001b[39m=\u001b[39;49mdate_parser,\n\u001b[0;32m    484\u001b[0m         thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m    485\u001b[0m         decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[0;32m    486\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[0;32m    487\u001b[0m         skipfooter\u001b[39m=\u001b[39;49mskipfooter,\n\u001b[0;32m    488\u001b[0m         convert_float\u001b[39m=\u001b[39;49mconvert_float,\n\u001b[0;32m    489\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39;49mmangle_dupe_cols,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[39m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    493\u001b[0m     \u001b[39mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1458\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m   1424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\n\u001b[0;32m   1425\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1426\u001b[0m     sheet_name: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1446\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, DataFrame] \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1447\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \u001b[39m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[39m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mparse(\n\u001b[0;32m   1459\u001b[0m         sheet_name\u001b[39m=\u001b[39msheet_name,\n\u001b[0;32m   1460\u001b[0m         header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   1461\u001b[0m         names\u001b[39m=\u001b[39mnames,\n\u001b[0;32m   1462\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m   1463\u001b[0m         usecols\u001b[39m=\u001b[39musecols,\n\u001b[0;32m   1464\u001b[0m         squeeze\u001b[39m=\u001b[39msqueeze,\n\u001b[0;32m   1465\u001b[0m         converters\u001b[39m=\u001b[39mconverters,\n\u001b[0;32m   1466\u001b[0m         true_values\u001b[39m=\u001b[39mtrue_values,\n\u001b[0;32m   1467\u001b[0m         false_values\u001b[39m=\u001b[39mfalse_values,\n\u001b[0;32m   1468\u001b[0m         skiprows\u001b[39m=\u001b[39mskiprows,\n\u001b[0;32m   1469\u001b[0m         nrows\u001b[39m=\u001b[39mnrows,\n\u001b[0;32m   1470\u001b[0m         na_values\u001b[39m=\u001b[39mna_values,\n\u001b[0;32m   1471\u001b[0m         parse_dates\u001b[39m=\u001b[39mparse_dates,\n\u001b[0;32m   1472\u001b[0m         date_parser\u001b[39m=\u001b[39mdate_parser,\n\u001b[0;32m   1473\u001b[0m         thousands\u001b[39m=\u001b[39mthousands,\n\u001b[0;32m   1474\u001b[0m         comment\u001b[39m=\u001b[39mcomment,\n\u001b[0;32m   1475\u001b[0m         skipfooter\u001b[39m=\u001b[39mskipfooter,\n\u001b[0;32m   1476\u001b[0m         convert_float\u001b[39m=\u001b[39mconvert_float,\n\u001b[0;32m   1477\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39mmangle_dupe_cols,\n\u001b[0;32m   1478\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1479\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:638\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# assume an integer if not a string\u001b[39;00m\n\u001b[0;32m    636\u001b[0m     sheet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[1;32m--> 638\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_sheet_data(sheet, convert_float)\n\u001b[0;32m    639\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(sheet, \u001b[39m\"\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    640\u001b[0m     \u001b[39m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[0;32m    641\u001b[0m     sheet\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:575\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[1;34m(self, sheet, convert_float)\u001b[0m\n\u001b[0;32m    573\u001b[0m data: \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[Scalar]] \u001b[39m=\u001b[39m []\n\u001b[0;32m    574\u001b[0m last_row_with_data \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m--> 575\u001b[0m \u001b[39mfor\u001b[39;00m row_number, row \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sheet\u001b[39m.\u001b[39mrows):\n\u001b[0;32m    576\u001b[0m     converted_row \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_cell(cell, convert_float) \u001b[39mfor\u001b[39;00m cell \u001b[39min\u001b[39;00m row]\n\u001b[0;32m    577\u001b[0m     \u001b[39mwhile\u001b[39;00m converted_row \u001b[39mand\u001b[39;00m converted_row[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    578\u001b[0m         \u001b[39m# trim trailing empty elements\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     75\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_source()\n\u001b[0;32m     76\u001b[0m parser \u001b[39m=\u001b[39m WorkSheetParser(src, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shared_strings,\n\u001b[0;32m     77\u001b[0m                          data_only\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mdata_only, epoch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mepoch,\n\u001b[0;32m     78\u001b[0m                          date_formats\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39m_date_formats)\n\u001b[1;32m---> 79\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m parser\u001b[39m.\u001b[39mparse():\n\u001b[0;32m     80\u001b[0m     \u001b[39mif\u001b[39;00m max_row \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m idx \u001b[39m>\u001b[39m max_row:\n\u001b[0;32m     81\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:144\u001b[0m, in \u001b[0;36mWorkSheetParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m properties \u001b[39m=\u001b[39m {\n\u001b[0;32m    126\u001b[0m     PRINT_TAG: (\u001b[39m'\u001b[39m\u001b[39mprint_options\u001b[39m\u001b[39m'\u001b[39m, PrintOptions),\n\u001b[0;32m    127\u001b[0m     MARGINS_TAG: (\u001b[39m'\u001b[39m\u001b[39mpage_margins\u001b[39m\u001b[39m'\u001b[39m, PageMargins),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m }\n\u001b[0;32m    142\u001b[0m it \u001b[39m=\u001b[39m iterparse(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource) \u001b[39m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m \u001b[39mfor\u001b[39;00m _, element \u001b[39min\u001b[39;00m it:\n\u001b[0;32m    145\u001b[0m     tag_name \u001b[39m=\u001b[39m element\u001b[39m.\u001b[39mtag\n\u001b[0;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m tag_name \u001b[39min\u001b[39;00m dispatcher:\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\xml\\etree\\ElementTree.py:1262\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[39myield from\u001b[39;00m pullparser\u001b[39m.\u001b[39mread_events()\n\u001b[0;32m   1261\u001b[0m \u001b[39m# load event buffer\u001b[39;00m\n\u001b[1;32m-> 1262\u001b[0m data \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mread(\u001b[39m16\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m1024\u001b[39;49m)\n\u001b[0;32m   1263\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[0;32m   1264\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\zipfile.py:924\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    923\u001b[0m \u001b[39mwhile\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n\u001b[1;32m--> 924\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read1(n)\n\u001b[0;32m    925\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[0;32m    926\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readbuffer \u001b[39m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\ABR\\anaconda3\\lib\\zipfile.py:1000\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_type \u001b[39m==\u001b[39m ZIP_DEFLATED:\n\u001b[0;32m    999\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m-> 1000\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(data, n)\n\u001b[0;32m   1001\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39meof \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m                  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m                  \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n\u001b[0;32m   1004\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "orders = pd.read_excel(r'C:\\Users\\ABR\\Downloads\\Orders.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\"Identify VIP and Preferred Customers\" is the non-technical goal of your boss. You need to translate that goal into technical languages that data analysts use:\n",
    "\n",
    "## How to label customers whose aggregated `amount_spent` is in a given quantile range?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We break down the main problem into several sub problems:\n",
    "\n",
    "#### Sub Problem 1: How to aggregate the  `amount_spent` for unique customers?\n",
    "\n",
    "#### Sub Problem 2: How to select customers whose aggregated `amount_spent` is in a given quantile range?\n",
    "\n",
    "#### Sub Problem 3: How to label selected customers as \"VIP\" or \"Preferred\"?\n",
    "\n",
    "*Note: If you want to break down the main problem in a different way, please feel free to revise the sub problems above.*\n",
    "\n",
    "Now in the workspace below, tackle each of the sub problems using the iterative problem solving workflow. Insert cells as necessary to write your codes and explain your steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# your code here\n",
    "#To aggreagate the amount_spent I aggregate it and group by the Customer ID\n",
    "#money spent by customer:\n",
    "agg_customer = orders.groupby('CustomerID', as_index=False).agg({'amount_spent':'sum'})\n",
    "agg_customer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_customer.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to identify the VIP customer, Prefered an dRegular customers I will first create customer labels\n",
    "cus_labels = ['Regular','Preffered', 'VIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then I will check what are the border values of three groups of clients that I want to label\n",
    "#I check min, max and values of two quantiles of 75% and 95%\n",
    "agg_min = agg_customer.min()\n",
    "agg_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_max = agg_customer.max()\n",
    "agg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_095 = agg_customer['amount_spent'].quantile(0.95)\n",
    "q_095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_075 = agg_customer['amount_spent'].quantile(0.75)\n",
    "q_075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I can divide clients into three groups and lebel them by creating a new columns and bins \n",
    "cutoffs = [0, 1661.64, 5840.2, 280206.02]\n",
    "agg_customer[\"label\"] = pd.cut(agg_customer['amount_spent'], cutoffs, labels=cus_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_customer.head(5)\n",
    "agg_customer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I check to confirm if maximum values in each group are corresponding to the values of the quantiles\n",
    "blabels_cust = agg_customer.groupby('label', as_index=False).agg({'amount_spent':'max'})\n",
    "blabels_cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I also check the number of customers in each label\n",
    "agg_customer['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll leave it to you to solve Q2 & Q3, which you can leverage from your solution for Q1:\n",
    "\n",
    "## Q2: How to identify which country has the most VIP Customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "orders.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_customer['CustomerID'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, I  merged to data frames to have everything in the same place\n",
    "merged_ord_label = orders.merge(agg_customer, on = 'CustomerID', how = 'left')\n",
    "merged_ord_label.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ord_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, I filter the dataset to have only VIP clients. I know that there are 217 VIPs.\n",
    "cust_VIP = merged_ord_label[(merged_ord_label['label']=='VIP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_VIP['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I group everything by CoustomerID and Country\n",
    "vip_by_count = cust_VIP.groupby(['CustomerID', 'Country'], as_index=False).agg({'label': 'count'})\n",
    "vip_by_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I can group it by country and count customers\n",
    "vip_by_count.groupby('Country',as_index=False).agg({'CustomerID': 'count'}).sort_values('CustomerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The largest number of VIP clients comes from United Kingdom\n",
    "vip_by_count.groupby('Country',as_index=False).agg({'CustomerID': 'count'}).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: How to identify which country has the most VIP+Preferred Customers combined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#I used previous code to find all customers that are not Regular\n",
    "cust_VIP_Pref= merged_ord_label[(merged_ord_label['label']!='Regular')] \n",
    "cust_VIP_Pref.value_counts('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I group everything by Country and I count ID\n",
    "\n",
    "vip_reg_by_count.groupby('Country',as_index=False).agg({'CustomerID': 'count'}).sort_values('CustomerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The highest number of both VIP and Prefered customers come from UK as well. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "a30add7c8e4d33a5bdb7043325678fb7a749884015e3f465812c6269e93fc9ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
